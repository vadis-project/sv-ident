{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import os\n",
    "import jsonlines\n",
    "import pandas as pd\n",
    "\n",
    "from beir.retrieval import models\n",
    "from beir.datasets.data_loader import GenericDataLoader\n",
    "from beir.retrieval.evaluation import EvaluateRetrieval\n",
    "from beir.retrieval.search.dense import DenseRetrievalExactSearch as DRES"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# === Set your hyperparameters here ===\n",
    "\n",
    "# Choose the dataset to use from [\"en\", \"de\"]\n",
    "lang = \"en\"\n",
    "assert lang in [\"en\", \"de\"]\n",
    "\n",
    "# Set to true if splitting the survey variables with sub-questions into separate corpus items\n",
    "sep_answers = False\n",
    "assert isinstance(sep_answers, bool)\n",
    "\n",
    "# The string used to join survey variable information\n",
    "join_str = \"[UNK]\"\n",
    "assert isinstance(join_str, str)\n",
    "\n",
    "# Evaluate each of the top k values\n",
    "k_values = [1, 3, 5, 10, 100]\n",
    "assert isinstance(k_values, list)\n",
    "all(isinstance(e, int) for e in k_values)\n",
    "\n",
    "# Embedding similarity function from [\"cos_sim\", \"dot_score\"]\n",
    "score_function = \"cos_sim\"\n",
    "assert score_function in [\"cos_sim\", \"dot_score\"]\n",
    "\n",
    "# Any sentence-transformers (https://www.sbert.net/docs/pretrained_models.html)\n",
    "# or HuggingFace model (https://huggingface.co/models) works \n",
    "pretrained_model = \"all-MiniLM-L6-v2\"\n",
    "\n",
    "# Set batch size for inference\n",
    "batch_size = 16\n",
    "assert isinstance(batch_size, int)\n",
    "\n",
    "# ================ End ================"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def split_variables(row):\n",
    "    if row not in [\"No\", \"NoSkip\"]:\n",
    "        return [tuple(x.split('-')) for x in row.replace('[','').replace(']','').split(',')]\n",
    "    else:\n",
    "        return [row]\n",
    "    \n",
    "def get_variables(row):\n",
    "    return [x[0] for x in row.variables]\n",
    "\n",
    "def make_label(row, answer, join_str):\n",
    "    v_id = row[\"v_id\"] if row[\"v_id\"] else \"\"\n",
    "    v_label = row[\"v_label\"] if row[\"v_label\"] else \"\"\n",
    "    v_topic = row[\"v_topic\"] if row[\"v_topic\"] else \"\"\n",
    "    v_question = row[\"v_question\"] if row[\"v_question\"] else \"\"\n",
    "    v_answer = answer if answer else \"\"\n",
    "\n",
    "    label = join_str.join([v_label, v_topic, v_question, v_answer])\n",
    "    \n",
    "    return label\n",
    "\n",
    "def get_labels(df, sep_answers=False, join_str=\"[UNK]\"):\n",
    "    ids = []\n",
    "    labels = []\n",
    "\n",
    "    df.fillna(\"\", inplace=True)\n",
    "\n",
    "    for i,row in df.iterrows():\n",
    "\n",
    "        if sep_answers:  # split survey variable answers into separate corpus items\n",
    "            answers = row[\"v_answer\"].split(\";\")\n",
    "        else:  # do not split survey variable answers\n",
    "            answers = [row[\"v_answer\"] if row[\"v_answer\"] else \"\"]\n",
    "            \n",
    "        for v_answer in answers:\n",
    "            v_id = row[\"v_id\"] if row[\"v_id\"] else \"\"\n",
    "            label = make_label(row, v_answer, join_str)\n",
    "            ids.append(v_id)\n",
    "            labels.append(label)\n",
    "    \n",
    "    return ids, labels"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Load raw data\n",
    "\n",
    "data_path = '../../data/trial/test/en.tsv' if lang != \"de\" else '../../data/trial/test/de.tsv'\n",
    "variables_path = '../../data/trial/vocabulary/en.tsv' if lang != \"de\" else '../../data/vocabulary/de.tsv'\n",
    "\n",
    "data_df = pd.read_csv(data_path, sep=\"\\t\")\n",
    "data_df.rename(columns={\"is_variable\": \"label\"}, inplace=True)\n",
    "data_df[\"variables\"] = data_df.variable.apply(lambda x: split_variables(x))\n",
    "\n",
    "variable_df = pd.read_csv(variables_path, sep=\"\\t\")\n",
    "\n",
    "ids, labels = get_labels(variable_df, sep_answers, join_str)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def make_beir_data(data_df, beir_data_dir):\n",
    "    queries = {}\n",
    "    qrels = {}\n",
    "    for i,row in data_df.iterrows():\n",
    "        queries[str(i)] = row.text\n",
    "        rel_labels = []\n",
    "        if row.variable not in [\"No\", \"NoSkip\"]:\n",
    "            rel_labels = [\"v\"+x for x in get_variables(row)]\n",
    "        qrels[str(i)] = rel_labels        \n",
    "\n",
    "    corpus = {}\n",
    "    for i,label in enumerate(labels):\n",
    "        corpus[ids[i]] = label\n",
    "\n",
    "    beir_qrels_dir = os.path.join(beir_data_dir, \"qrels\")\n",
    "    if not os.path.exists(beir_qrels_dir):\n",
    "        os.makedirs(beir_qrels_dir)\n",
    "\n",
    "    queries_beir = []\n",
    "    for k,v in queries.items():\n",
    "        queries_beir.append({\"_id\": k, \"text\": v})\n",
    "\n",
    "    corpus_beir = []\n",
    "    for k,v in corpus.items():\n",
    "        corpus_beir.append({\"_id\": k, \"title\": \"\", \"text\": v})\n",
    "        # corpus_beir.append({\"_id\": k, \"title\": f\"Doc_{str(k)}\", \"text\": v})\n",
    "\n",
    "    qrels_beir = {\"query-id\": [], \"corpus-id\": [], \"score\": []}\n",
    "\n",
    "    for k,vals in qrels.items():\n",
    "        for v in vals:\n",
    "            qrels_beir[\"query-id\"].append(k)\n",
    "            qrels_beir[\"corpus-id\"].append(v)\n",
    "            qrels_beir[\"score\"].append(1)\n",
    "\n",
    "    df = pd.DataFrame.from_records(qrels_beir)\n",
    "    df[[\"query-id\", \"corpus-id\", \"score\"]].to_csv(os.path.join(beir_data_dir, \"qrels\", \"all.tsv\"), index=False, sep=\"\\t\")\n",
    "\n",
    "    with jsonlines.open(os.path.join(beir_data_dir, \"queries.jsonl\"), \"w\") as writer:\n",
    "        writer.write_all(queries_beir)\n",
    "\n",
    "    with jsonlines.open(os.path.join(beir_data_dir, \"corpus.jsonl\"), \"w\") as writer:\n",
    "        writer.write_all(corpus_beir)\n",
    "    \n",
    "    return queries_beir, corpus_beir, qrels_beir"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Load data in BEIR format\n",
    "\n",
    "beir_data_dir = f\"../../data/trial/beir_data/{lang}\"\n",
    "_queries_beir, _corpus_beir, _qrels_beir = make_beir_data(data_df, beir_data_dir)\n",
    "\n",
    "corpus, queries, qrels = GenericDataLoader(data_folder=beir_data_dir).load(split=\"all\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Initialize retriever model\n",
    "\n",
    "model = DRES(models.SentenceBERT(pretrained_model), batch_size=batch_size)\n",
    "retriever = EvaluateRetrieval(model, score_function=score_function, k_values=k_values)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Evaluate model using multiple metrics\n",
    "\n",
    "results = retriever.retrieve(corpus, queries, return_sorted=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Save files\n",
    "\n",
    "import json\n",
    "\n",
    "path = \"./qrels.json\"\n",
    "with open(path, \"w\") as fp:\n",
    "    json.dump(qrels, fp)\n",
    "\n",
    "path = \"./run.json\"\n",
    "with open(path, \"w\") as fp:\n",
    "    json.dump(results, fp)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('venv': venv)"
  },
  "interpreter": {
   "hash": "d9c75a10141fb9765b6dd95572dd5e09c2b8655ce454a09c7fa750dc40f7865b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}